## Future Feature Implementation Plan

#### **Initiative 1: Trust & Transparency (Source Citations)**

**Goal:** Enhance user trust by making the AI's answers verifiable with clear links to source material.

*   **Backend Tasks:**
    *   **Task `BE-CITE-001`:** Modify the RAG prompt template in `backend/rag_pipeline.py` to instruct the LLM to insert citation markers (e.g., `[source_1]`) within its generated answer.
    *   **Task `BE-CITE-002`:** Update the document formatting logic in `rag_pipeline.py` to prepend a unique identifier (e.g., `[source_1]: ...`) to each document chunk before it is passed to the LLM.

*   **Frontend Tasks:**
    *   **Task `FE-CITE-001`:** In `src/app/page.tsx`, implement a function to parse the AI's answer string for citation markers using a regular expression.
    *   **Task `FE-CITE-002`:** Modify the `src/components/Message.tsx` component to transform the parsed citation markers into interactive UI elements (e.g., tooltips or accordions) that reveal the corresponding source's metadata upon user interaction.

---

#### **Initiative 2: Dynamic & Interactive Experience**

**Goal:** Make the chat interface feel more responsive with streaming and more helpful with proactive suggestions.

*   **Backend Tasks:**
    *   **Task `BE-STREAM-001`:** Refactor the `/api/v1/chat` endpoint in `backend/main.py` and the `query` method in `backend/rag_pipeline.py` to be asynchronous, returning a `StreamingResponse` by using the `rag_chain.astream()` method.
    *   **Task `BE-SUGGEST-001`:** In `backend/rag_pipeline.py`, create a new, separate LLM chain with a dedicated prompt template designed to generate 3-4 relevant follow-up questions based on the conversation history.
    *   **Task `BE-SUGGEST-002`:** To keep streaming and suggested questions separate, create a new endpoint `POST /api/v1/suggest-questions`. This endpoint will take the conversation history and generate suggestions. Update `backend/data_models.py` with the necessary request/response models.
    *   **Task `BE-SUGGEST-003`:** Implement the logic for the new endpoint in a new router file.

*   **Frontend Tasks:**
    *   **Task `FE-STREAM-001`:** In `src/app/page.tsx`, update the `handleSendMessage` function to read the streaming response body, appending incoming text chunks to the current message state to create a "typing" effect.
    *   **Task `FE-SUGGEST-001`:** After the main answer stream is complete, make a subsequent `fetch` call to the new `/api/v1/suggest-questions` endpoint.
    *   **Task `FE-SUGGEST-002`:** Render the returned `suggested_questions` as clickable buttons beneath the completed AI response.

---

#### **Initiative 3: Upgraded Retrieval Engine**

**Goal:** Improve the relevance and accuracy of retrieved documents, leading to higher-quality answers.

*   **Backend Tasks:**
    *   **Task `BE-HYBRID-001`:** Update the MongoDB Atlas Vector Search index definition to include operators for keyword-based search (e.g., `search`) alongside `vectorSearch`. Document this change in `cline_docs/techStack.md`.
    *   **Task `BE-HYBRID-002`:** Modify the retriever initialization in `rag_pipeline.py` to use a custom aggregation pipeline that performs a hybrid search, combining vector similarity with keyword matching.
    *   **Task `BE-RERANK-001`:** Add a re-ranking library, such as `cohere` or `sentence-transformers`, to `backend/requirements.txt`.
    *   **Task `BE-RERANK-002`:** Integrate a re-ranker component (e.g., `CohereRerank`) into the RAG chain in `rag_pipeline.py`. This involves increasing the initial number of retrieved documents (e.g., `k=20`) and then using the re-ranker to pass the top 5 most relevant documents to the LLM.

*   **Frontend Tasks:**
    *   None. This is a backend-only enhancement.

---

#### **Initiative 4: User Feedback Loop**

**Goal:** Implement a mechanism to collect user feedback on answer quality, providing data for future system improvements.

*   **Backend Tasks:**
    *   **Task `BE-FEEDBACK-001`:** In `backend/data_models.py`, create a new Pydantic model `FeedbackRequest` to structure incoming feedback data (e.g., `chat_history`, `answer`, `rating`).
    *   **Task `BE-FEEDBACK-002`:** Create a new API router, `backend/api/v1/feedback.py`, with a `POST /api/v1/feedback` endpoint.
    *   **Task `BE-FEEDBACK-003`:** Implement the endpoint logic to receive the `FeedbackRequest` and log its contents to a dedicated `feedback_logs` collection in MongoDB.
    *   **Task `BE-FEEDBACK-004`:** Integrate the new feedback router into the main FastAPI application in `backend/main.py`.

*   **Frontend Tasks:**
    *   **Task `FE-FEEDBACK-001`:** In `src/components/Message.tsx`, add UI elements (e.g., üëç/üëé buttons) to messages generated by the AI.
    *   **Task `FE-FEEDBACK-002`:** In `src/app/page.tsx`, implement state management to track the feedback status for each message, preventing multiple submissions.
    *   **Task `FE-FEEDBACK-003`:** Create a handler function that captures the relevant conversation context and sends it to the `/api/v1/feedback` endpoint when a feedback button is clicked.
